---
title: Complex Embeddings for Simple Link Prediction
isOriginal: true
icon: note
date: 2022-10-18
star: 5
category:
  - KRL
tag:
  - KG
  - STAR-4
---

- 第一篇将复数空间引入知识图谱嵌入的文献。
- 复数空间中的共轭向量使得传统的点积可以在不对称关系中用起来。
- ComplEx 模型主要受 DistMult 模型的启发，做了一些改进，但这个改进非常精妙。

## 1. 模型讲解

这篇文章主要是解决 link prediction 问题。ComplEx 是基于语义匹配的模型，它将 link prediction 任务看成是一个 3D 的二元 tensor 的补全问题。这种方式就是将观测到的 tensor 分解成秩较小的 embedding matrices 的乘积，从而为每个 entity 和 relation 生成固定尺寸的 vector representation。

### 1.1 引入复数空间

一个好的 relational model 应该具有如下两个特点：

+ 能够学习出关系的 reflexivity/irreflexivity、symmetry/antisymmetry 和 transitivity 的特点；
+ 其算法在时间和内存的扩充都是随着 KB 增长而线性增长的。

Embedding 做 dot product 是 scale well 的，并且由于其数学上的可交换性，它可以很自然地处理 symmetry 和 reflexivity/irreflexivity 的 relations，但是它在处理 antisymmetry 的 relation 时却是困难的。像 RESCAL 的关系矩阵 $R_k$ 是非对称的情况下，才能建模非对称关系，但这样参数量巨大，为了降低参数量，DistMult 将关系限制为对角阵，虽然参数量降下来了，但是只能建模对称关系了。

而如果换成复数，用 complex vector 就可以描述非对称关系了，同时也还能保留 dot product 的效率优势（即空间和时间的复杂度均为线性）。

### 1.2 只有一个 relation 的情况

#### 1.2.1 符号说明

+ 只有一个 relation
+ $\varepsilon$ 代表 entities 的 set，一共有 n 个 entity
+ $Y\in \mathbb{R}^{n \times n}$ 表示 the partially observed sign matrix，如果两个 entities 之间具有 relation，则 $Y_{so}=1$，否则 $Y_{so}=-1$
+ $X \in \mathbb{R}^{n \times n}$ 是 latent matrix of scores

$X$ 与 $Y$ 之间的关系：$P(Y_{so}=1)=\sigma(X_{so})$

#### 1.2.2 奇异值分解（SVD）

我们的目的是找到一个更加灵活地表示 KB 中事实的 X 的 generic structure。

SVD 矩阵分解可以施加于任何矩阵，其公式如下：

$$X \approx UV^T$$

其中 $U$ 和 $V$ 都是两个在功能上独立的 $n \times K$ 的 matrix，K 是 matrix 的 rank。

如果采用这种形式，那么就假定了 entity 出现在 subject 和出现在 object 的位置上会有不同的 representation。但是在许多 link prediction 问题中，相同的 entity 在 subject 和 object 具有相同的 embedding 是更自然的，因此引出下面的研究。

#### 1.2.3 特征值分解（EVD）



